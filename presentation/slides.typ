#import "@preview/diatypst:0.8.0": *

#show: slides.with(
  title: "Introduction to Explainable AI",
  subtitle: "Deep Learning Tutorial",
  date: "2025-12-11",
  authors: "Names...",
  title-color: rgb("#BA0020").darken(10%),
  count: "number",
)

= xAI in Public Policy

== Motivation // Luis

Why xAI?

- Transparency is essential for ethical AI deployment
- Need to understand, trust and govern AI systems, especially when deployed in government-contexts
- Real cases
  - COMPAS recidivism tool
  - Medical triage algorithms
  - Automated eligibility systems

- Regulation is catching up: OECD guidelines and the EU AI Act demand clear explanations, bias checks and human oversight for high-risk systems

- Tradeoff: Performace vs Interpretability?

== Case 1

#lorem(20)

== Case 2

#lorem(20)

= Methods

== Landscape // Luis

#lorem(20)

== Our Case // Franco

// Present Case (Franco)

#lorem(20)

== LIME // Franco

#lorem(20)

== Counterfactual Explanations // Franco

#lorem(20)

== SHAP // Franco

#lorem(20)

= Takeaways // Luis

- At core: Human interpretability
- Inherently interpretable first
- Ethical use of black box models
- Explanability methods useful but limited

= Q&A
